{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Penalty experiments -----------\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.150036\n",
      "         Iterations: 117\n",
      "         Function evaluations: 213\n",
      "         Gradient evaluations: 201\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.156098\n",
      "         Iterations: 142\n",
      "         Function evaluations: 184\n",
      "         Gradient evaluations: 173\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.162070\n",
      "         Iterations: 178\n",
      "         Function evaluations: 269\n",
      "         Gradient evaluations: 257\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.139209\n",
      "         Iterations: 151\n",
      "         Function evaluations: 210\n",
      "         Gradient evaluations: 198\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166793\n",
      "         Iterations: 141\n",
      "         Function evaluations: 237\n",
      "         Gradient evaluations: 225\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.159459\n",
      "         Iterations: 116\n",
      "         Function evaluations: 191\n",
      "         Gradient evaluations: 179\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.165470\n",
      "         Iterations: 205\n",
      "         Function evaluations: 272\n",
      "         Gradient evaluations: 261\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.163435\n",
      "         Iterations: 201\n",
      "         Function evaluations: 307\n",
      "         Gradient evaluations: 295\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.167240\n",
      "         Iterations: 190\n",
      "         Function evaluations: 242\n",
      "         Gradient evaluations: 230\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.140669\n",
      "         Iterations: 145\n",
      "         Function evaluations: 214\n",
      "         Gradient evaluations: 203\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.168389\n",
      "         Iterations: 50\n",
      "         Function evaluations: 133\n",
      "         Gradient evaluations: 121\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.173313\n",
      "         Iterations: 52\n",
      "         Function evaluations: 147\n",
      "         Gradient evaluations: 135\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.179685\n",
      "         Iterations: 52\n",
      "         Function evaluations: 150\n",
      "         Gradient evaluations: 138\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.160444\n",
      "         Iterations: 52\n",
      "         Function evaluations: 151\n",
      "         Gradient evaluations: 139\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.184703\n",
      "         Iterations: 52\n",
      "         Function evaluations: 116\n",
      "         Gradient evaluations: 105\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.178486\n",
      "         Iterations: 51\n",
      "         Function evaluations: 96\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.183714\n",
      "         Iterations: 51\n",
      "         Function evaluations: 143\n",
      "         Gradient evaluations: 131\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.181228\n",
      "         Iterations: 76\n",
      "         Function evaluations: 180\n",
      "         Gradient evaluations: 168\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.184322\n",
      "         Iterations: 76\n",
      "         Function evaluations: 167\n",
      "         Gradient evaluations: 155\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.158054\n",
      "         Iterations: 54\n",
      "         Function evaluations: 151\n",
      "         Gradient evaluations: 139\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.178799\n",
      "         Iterations: 50\n",
      "         Function evaluations: 106\n",
      "         Gradient evaluations: 94\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.183158\n",
      "         Iterations: 51\n",
      "         Function evaluations: 98\n",
      "         Gradient evaluations: 87\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.189686\n",
      "         Iterations: 50\n",
      "         Function evaluations: 98\n",
      "         Gradient evaluations: 87\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.171588\n",
      "         Iterations: 47\n",
      "         Function evaluations: 149\n",
      "         Gradient evaluations: 137\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.194785\n",
      "         Iterations: 46\n",
      "         Function evaluations: 144\n",
      "         Gradient evaluations: 132\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.189159\n",
      "         Iterations: 49\n",
      "         Function evaluations: 96\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.193775\n",
      "         Iterations: 46\n",
      "         Function evaluations: 91\n",
      "         Gradient evaluations: 80\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.193162\n",
      "         Iterations: 48\n",
      "         Function evaluations: 151\n",
      "         Gradient evaluations: 139\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.195870\n",
      "         Iterations: 45\n",
      "         Function evaluations: 135\n",
      "         Gradient evaluations: 123\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.168049\n",
      "         Iterations: 48\n",
      "         Function evaluations: 146\n",
      "         Gradient evaluations: 134\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.188138\n",
      "         Iterations: 35\n",
      "         Function evaluations: 135\n",
      "         Gradient evaluations: 123\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.191331\n",
      "         Iterations: 48\n",
      "         Function evaluations: 132\n",
      "         Gradient evaluations: 120\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.197928\n",
      "         Iterations: 50\n",
      "         Function evaluations: 96\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.180539\n",
      "         Iterations: 48\n",
      "         Function evaluations: 114\n",
      "         Gradient evaluations: 104\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.203093\n",
      "         Iterations: 43\n",
      "         Function evaluations: 101\n",
      "         Gradient evaluations: 91\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.197871\n",
      "         Iterations: 48\n",
      "         Function evaluations: 108\n",
      "         Gradient evaluations: 97\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.202051\n",
      "         Iterations: 45\n",
      "         Function evaluations: 88\n",
      "         Gradient evaluations: 76\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.201809\n",
      "         Iterations: 48\n",
      "         Function evaluations: 149\n",
      "         Gradient evaluations: 137\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.204123\n",
      "         Iterations: 47\n",
      "         Function evaluations: 147\n",
      "         Gradient evaluations: 135\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.176262\n",
      "         Iterations: 52\n",
      "         Function evaluations: 152\n",
      "         Gradient evaluations: 140\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.195258\n",
      "         Iterations: 51\n",
      "         Function evaluations: 154\n",
      "         Gradient evaluations: 142\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.198402\n",
      "         Iterations: 56\n",
      "         Function evaluations: 170\n",
      "         Gradient evaluations: 158\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.205093\n",
      "         Iterations: 48\n",
      "         Function evaluations: 103\n",
      "         Gradient evaluations: 92\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.188382\n",
      "         Iterations: 49\n",
      "         Function evaluations: 151\n",
      "         Gradient evaluations: 139\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.210282\n",
      "         Iterations: 49\n",
      "         Function evaluations: 139\n",
      "         Gradient evaluations: 127\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.205470\n",
      "         Iterations: 50\n",
      "         Function evaluations: 152\n",
      "         Gradient evaluations: 140\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.209235\n",
      "         Iterations: 44\n",
      "         Function evaluations: 140\n",
      "         Gradient evaluations: 128\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.212456\n",
      "         Iterations: 29\n",
      "         Function evaluations: 86\n",
      "         Gradient evaluations: 75\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.211339\n",
      "         Iterations: 46\n",
      "         Function evaluations: 176\n",
      "         Gradient evaluations: 164\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.185474\n",
      "         Iterations: 33\n",
      "         Function evaluations: 112\n",
      "         Gradient evaluations: 100\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.201590\n",
      "         Iterations: 54\n",
      "         Function evaluations: 124\n",
      "         Gradient evaluations: 113\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.206094\n",
      "         Iterations: 32\n",
      "         Function evaluations: 125\n",
      "         Gradient evaluations: 113\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.211544\n",
      "         Iterations: 52\n",
      "         Function evaluations: 168\n",
      "         Gradient evaluations: 156\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.195627\n",
      "         Iterations: 48\n",
      "         Function evaluations: 155\n",
      "         Gradient evaluations: 143\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.216806\n",
      "         Iterations: 44\n",
      "         Function evaluations: 142\n",
      "         Gradient evaluations: 130\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.214228\n",
      "         Iterations: 28\n",
      "         Function evaluations: 84\n",
      "         Gradient evaluations: 73\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.215804\n",
      "         Iterations: 47\n",
      "         Function evaluations: 140\n",
      "         Gradient evaluations: 128\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.215901\n",
      "         Iterations: 52\n",
      "         Function evaluations: 159\n",
      "         Gradient evaluations: 147\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.218256\n",
      "         Iterations: 39\n",
      "         Function evaluations: 132\n",
      "         Gradient evaluations: 120\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.191240\n",
      "         Iterations: 29\n",
      "         Function evaluations: 127\n",
      "         Gradient evaluations: 115\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.207075\n",
      "         Iterations: 38\n",
      "         Function evaluations: 93\n",
      "         Gradient evaluations: 82\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.211103\n",
      "         Iterations: 43\n",
      "         Function evaluations: 150\n",
      "         Gradient evaluations: 138\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.217827\n",
      "         Iterations: 45\n",
      "         Function evaluations: 103\n",
      "         Gradient evaluations: 92\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.202665\n",
      "         Iterations: 29\n",
      "         Function evaluations: 126\n",
      "         Gradient evaluations: 114\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.223175\n",
      "         Iterations: 42\n",
      "         Function evaluations: 153\n",
      "         Gradient evaluations: 141\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.218805\n",
      "         Iterations: 44\n",
      "         Function evaluations: 105\n",
      "         Gradient evaluations: 94\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.221667\n",
      "         Iterations: 38\n",
      "         Function evaluations: 81\n",
      "         Gradient evaluations: 70\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.223550\n",
      "         Iterations: 30\n",
      "         Function evaluations: 127\n",
      "         Gradient evaluations: 115\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.223747\n",
      "         Iterations: 37\n",
      "         Function evaluations: 138\n",
      "         Gradient evaluations: 126\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.196392\n",
      "         Iterations: 30\n",
      "         Function evaluations: 138\n",
      "         Gradient evaluations: 126\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.212242\n",
      "         Iterations: 38\n",
      "         Function evaluations: 92\n",
      "         Gradient evaluations: 82\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.216454\n",
      "         Iterations: 33\n",
      "         Function evaluations: 87\n",
      "         Gradient evaluations: 76\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.223088\n",
      "         Iterations: 41\n",
      "         Function evaluations: 107\n",
      "         Gradient evaluations: 95\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.207876\n",
      "         Iterations: 40\n",
      "         Function evaluations: 118\n",
      "         Gradient evaluations: 108\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.228205\n",
      "         Iterations: 37\n",
      "         Function evaluations: 83\n",
      "         Gradient evaluations: 72\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.223928\n",
      "         Iterations: 38\n",
      "         Function evaluations: 133\n",
      "         Gradient evaluations: 121\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.227296\n",
      "         Iterations: 43\n",
      "         Function evaluations: 107\n",
      "         Gradient evaluations: 96\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.228567\n",
      "         Iterations: 28\n",
      "         Function evaluations: 81\n",
      "         Gradient evaluations: 69\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.229387\n",
      "         Iterations: 42\n",
      "         Function evaluations: 89\n",
      "         Gradient evaluations: 78\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.201303\n",
      "         Iterations: 28\n",
      "         Function evaluations: 109\n",
      "         Gradient evaluations: 97\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.222163\n",
      "         Iterations: 19\n",
      "         Function evaluations: 63\n",
      "         Gradient evaluations: 52\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.221247\n",
      "         Iterations: 33\n",
      "         Function evaluations: 86\n",
      "         Gradient evaluations: 75\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.227778\n",
      "         Iterations: 37\n",
      "         Function evaluations: 88\n",
      "         Gradient evaluations: 77\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.212932\n",
      "         Iterations: 36\n",
      "         Function evaluations: 98\n",
      "         Gradient evaluations: 86\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.233465\n",
      "         Iterations: 37\n",
      "         Function evaluations: 90\n",
      "         Gradient evaluations: 79\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.229532\n",
      "         Iterations: 43\n",
      "         Function evaluations: 111\n",
      "         Gradient evaluations: 99\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.231746\n",
      "         Iterations: 37\n",
      "         Function evaluations: 137\n",
      "         Gradient evaluations: 125\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.233312\n",
      "         Iterations: 27\n",
      "         Function evaluations: 124\n",
      "         Gradient evaluations: 112\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.233840\n",
      "         Iterations: 38\n",
      "         Function evaluations: 143\n",
      "         Gradient evaluations: 131\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.205780\n",
      "         Iterations: 29\n",
      "         Function evaluations: 74\n",
      "         Gradient evaluations: 62\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.221512\n",
      "         Iterations: 40\n",
      "         Function evaluations: 154\n",
      "         Gradient evaluations: 142\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.225406\n",
      "         Iterations: 42\n",
      "         Function evaluations: 153\n",
      "         Gradient evaluations: 141\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.232182\n",
      "         Iterations: 40\n",
      "         Function evaluations: 157\n",
      "         Gradient evaluations: 145\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.217701\n",
      "         Iterations: 34\n",
      "         Function evaluations: 107\n",
      "         Gradient evaluations: 95\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.238015\n",
      "         Iterations: 43\n",
      "         Function evaluations: 90\n",
      "         Gradient evaluations: 78\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.233781\n",
      "         Iterations: 44\n",
      "         Function evaluations: 140\n",
      "         Gradient evaluations: 128\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.236709\n",
      "         Iterations: 36\n",
      "         Function evaluations: 93\n",
      "         Gradient evaluations: 82\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.237622\n",
      "         Iterations: 28\n",
      "         Function evaluations: 122\n",
      "         Gradient evaluations: 110\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.238563\n",
      "         Iterations: 36\n",
      "         Function evaluations: 137\n",
      "         Gradient evaluations: 125\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.210112\n",
      "         Iterations: 28\n",
      "         Function evaluations: 103\n",
      "         Gradient evaluations: 92\n",
      "best_lambda =  1.1\n",
      "Coefficients =  [-4.59103183] [[ -4.31281330e-01  -1.30743957e-01   0.00000000e+00   2.68211499e-01\n",
      "    1.21209729e+00   7.91820128e-01   2.97204882e+00   1.42216677e+00\n",
      "    5.39792994e-02   3.38639116e-01  -8.03650561e-02  -4.81583056e-01\n",
      "   -4.78072503e-01   2.18194381e-01   0.00000000e+00   1.50275566e+00\n",
      "    1.43649483e+00   0.00000000e+00   3.72954850e-01   3.22283488e-01\n",
      "    4.95142012e-01   4.14439019e-01   1.86537513e+00   1.35042842e+00\n",
      "   -3.58748905e+00  -2.83744493e-01  -9.19250743e+00   0.00000000e+00\n",
      "   -8.07769511e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   -8.48520519e-01   0.00000000e+00  -5.48835601e-01   1.09985274e+00\n",
      "   -7.49404435e-01   0.00000000e+00  -9.97208811e-01   0.00000000e+00\n",
      "   -7.55531344e-01  -2.72150778e+00  -1.31698674e+00  -1.99156921e+00\n",
      "   -1.23549176e+00  -3.07991391e+00   0.00000000e+00  -2.58466934e+00\n",
      "   -1.52518232e+00  -4.72735635e-01   0.00000000e+00   2.03634247e+00\n",
      "    5.69434854e+00   5.45517652e-03   6.98881577e-01   1.66940314e-01\n",
      "    4.26860752e-01]]\n",
      "Accuracy on set aside test set for  logt  =  0.9453125\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "# No modifications in this script\n",
    "# complete the functions in util.py; then run the script\n",
    "\n",
    "# load the spam data in\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,type,penalty):\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print \"best_lambda = \", best_lambda\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print \"Coefficients = \", lreg.intercept_,lreg.coef_\n",
    "    predy = lreg.predict(Xt)\n",
    "    print \"Accuracy on set aside test set for \", type, \" = \", np.mean(predy==ytest)\n",
    "\n",
    "print \"L2 Penalty experiments -----------\"\n",
    "#run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "#run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "#run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "#print \"L1 Penalty experiments -----------\"\n",
    "#run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "#run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
